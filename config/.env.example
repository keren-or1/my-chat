# Ollama Chat Application Configuration
# Copy this file to .env and update values as needed

# Ollama Service Configuration
OLLAMA_API_URL=http://localhost:11434/api
OLLAMA_MODEL=tinyllama
OLLAMA_TIMEOUT=300

# FastAPI Server Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_LOG_LEVEL=info
API_RELOAD=false

# LLM Model Parameters
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.9
LLM_TOP_K=40

# Health Check Configuration
HEALTH_CHECK_INTERVAL=5
HEALTH_CHECK_TIMEOUT=2

# CORS Configuration
CORS_ORIGINS=["*"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["*"]
CORS_ALLOW_HEADERS=["*"]

# Logging Configuration
LOG_LEVEL=info
LOG_FORMAT=json

# Application Information
APP_NAME="Ollama Chat Application"
APP_VERSION="1.0.0"
